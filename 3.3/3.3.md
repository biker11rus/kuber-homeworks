# Домашнее задание к занятию "Как работает сеть в K8S"

### Цель задания

Настроить сетевую политику доступа к подам.

### Чеклист готовности к домашнему заданию

1. Кластер k8s с установленным сетевым плагином calico

### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Документация Calico](https://www.tigera.io/project-calico/)
2. [Network Policy](https://kubernetes.io/docs/concepts/services-networking/network-policies/)
3. [About Network Policy](https://docs.projectcalico.org/about/about-network-policy)

-----

### Задание 1. Создать сетевую политику (или несколько политик) для обеспечения доступа

1. Создать deployment'ы приложений frontend, backend и cache и соответсвующие сервисы.
2. В качестве образа использовать network-multitool.
3. Разместить поды в namespace app.
4. Создать политики чтобы обеспечить доступ frontend -> backend -> cache. Другие виды подключений должны быть запрещены.
5. Продемонстрировать, что трафик разрешен и запрещен.

### Ответ

Развернут кластер из 3 нод (1 контролплейн, 2 воркер) в ЯК с помощью терраформ, настроено подключение kubectl c хостовой машины   

1. Создаем namespace 
```
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl create namespace app
namespace/app created
```
2. Применяем деплойменты  
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./main/10-frontend.yaml 
deployment.apps/frontend created
service/frontend created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./main/20-backend.yaml 
deployment.apps/backend created
service/backend created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./main/30-cache.yaml 
deployment.apps/cache created
service/cache created
```
3. Меняем namespace в дефолтном контексе на app  
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl config set-context --current --namespace=app
Context "kubernetes-admin@test_cluster" modified.
```
4. Смотрим поды, сервисы, сетевые политики, и CNI плагин
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl get pods -o wide 
NAME                        READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES
backend-7f6ffd4fb4-kbx8p    1/1     Running   0          94s   10.233.75.2   node2   <none>           <none>
cache-7bb8f4764b-25fl8      1/1     Running   0          91s   10.233.71.3   node3   <none>           <none>
frontend-85f54fff68-pgdlf   1/1     Running   0          99s   10.233.71.2   node3   <none>           <none>
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl get svc -o wide 
NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE    SELECTOR
backend    ClusterIP   10.233.62.49   <none>        80/TCP    107s   app=backend
cache      ClusterIP   10.233.61.51   <none>        80/TCP    104s   app=cache
frontend   ClusterIP   10.233.22.32   <none>        80/TCP    112s   app=frontend
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl get networkpolicies -o wide 
No resources found in app namespace.
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS      AGE
calico-kube-controllers-7b9cddc446-r5n4p   1/1     Running   0             53m
calico-node-4w6f5                          1/1     Running   1 (53m ago)   54m
calico-node-5b4gj                          1/1     Running   0             54m
calico-node-k2msg                          1/1     Running   0             54m
coredns-68868dc95b-m77kc                   1/1     Running   0             52m
coredns-68868dc95b-vklvs                   1/1     Running   0             52m
dns-autoscaler-7ccd65764f-bxctg            1/1     Running   0             52m
kube-apiserver-node1                       1/1     Running   1             56m
kube-controller-manager-node1              1/1     Running   1             56m
kube-proxy-d5k9m                           1/1     Running   0             55m
kube-proxy-hpphq                           1/1     Running   0             55m
kube-proxy-ms9l5                           1/1     Running   0             55m
kube-scheduler-node1                       1/1     Running   1             56m
nginx-proxy-node2                          1/1     Running   0             53m
nginx-proxy-node3                          1/1     Running   0             53m
nodelocaldns-cm6xq                         1/1     Running   0             52m
nodelocaldns-lkg4j                         1/1     Running   0             52m
nodelocaldns-mnhvj                         1/1     Running   0             52m
```
5. Проверяем что всё доступно  
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec frontend-85f54fff68-pgdlf -- curl backend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    79  100    79    0     0  12040      0 --:--:-- --:--:-- --:--:-- 13166
Praqma Network MultiTool (with NGINX) - backend-7f6ffd4fb4-kbx8p - 10.233.75.2
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec backend-7f6ffd4fb4-kbx8p -- curl cache
Praqma Network MultiTool (with NGINX) - cache-7bb8f4764b-25fl8 - 10.233.71.3
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    77  100    77    0     0   8895      0 --:--:-- --:--:-- --:--:--  9625
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec cache-7bb8f4764b-25fl8 -- curl frontend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    80  100    80    0     0   7228      0 --:--:-- --:--:-- --:--:--  7272
Praqma Network MultiTool (with NGINX) - frontend-85f54fff68-pgdlf - 10.233.71.2
```
6. Применим политики запрета всего и проверим 
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./network-policy/00-default-deny-ingress.yaml 
networkpolicy.networking.k8s.io/default-deny-ingress created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./network-policy/10-default-deny-egress.yaml 
networkpolicy.networking.k8s.io/default-deny-egress created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec frontend-85f54fff68-pgdlf -- curl backend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0curl: (6) Could not resolve host: backend
```  
Ошибка Could not resolve host значит нужно разрешить днс (53 порт UDP)- разрешаем (можно более точечно разрешать днс, запрещая запросы за пределы кластера, но в рамках ДЗ это излишне) проверяем  
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./network-policy/20-allow-egress-dns.yaml 
networkpolicy.networking.k8s.io/allow-egress-dns created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec cache-7bb8f4764b-25fl8 -- curl -m 3 frontend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0
curl: (28) Connection timed out after 3001 milliseconds
command terminated with exit code 28
```
ДНС работает, но соединения нет как и было задумано политикой по умолчанию
7. Разрешим соединения frontend -> backend, по порту 80 TCP
Разрешим входящие подключения (ingress) на порт 80 с frontend to backend и проверим 
```bash 
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./network-policy/30-allow-ingress-backend.yaml 
networkpolicy.networking.k8s.io/allow-ingress-backend created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec frontend-85f54fff68-pgdlf -- curl -m 2 backend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
curl: (28) Connection timed out after 2000 milliseconds
command terminated with exit code 28
```
Соединения нет, так как нужно разрешить исходящие соединения c frontend на backend (порт не указываем так как TCP соединение и локальный порт будет выбран случаиным образом) добавляем политику и проверяем 
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl apply -f ./network-policy/40-allow-egress-frontend.yaml 
networkpolicy.networking.k8s.io/allow-egress-frontend created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec frontend-85f54fff68-pgdlf -- curl -m 2 backend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Praqma Network MultiTool (with NGINX) - backend-7f6ffd4fb4-kbx8p - 10.233.75.2
100    79  100    79    0     0  13962      0 --:--:-- --:--:-- --:--:-- 15800
```
Проверим отсутствие соединения в обратную сторону
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3$ kubectl exec backend-7f6ffd4fb4-kbx8p -- curl -m 2 frontend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
curl: (28) Connection timed out after 2000 milliseconds
command terminated with exit code 28
```
8. По аналогии разрешим соединение backend -> cache (пересоздал поды, имена будут отличаться) и проверим 

```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3/network-policy$ kubectl apply -f ./50-allow-ingress-cache.yaml 
networkpolicy.networking.k8s.io/allow-ingress-cache created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3/network-policy$ kubectl apply -f ./60-allow-egress-backend.yaml 
networkpolicy.networking.k8s.io/allow-egress-backend created
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3/network-policy$ kubectl exec backend-7f6ffd4fb4-wzv68 -- curl cache
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Praqma Network MultiTool (with NGINX) - cache-7bb8f4764b-q9pgj - 10.233.71.4
100    77  100    77    0     0   9729      0 --:--:-- --:--:-- --:--:-- 11000
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3/network-policy$ kubectl exec cache-7bb8f4764b-q9pgj -- curl -m 2 backend
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
curl: (28) Connection timed out after 2000 milliseconds
command terminated with exit code 28
```
Итоговые политики 
```bash
rkhozyainov@rkhozyainov-T530-ubuntu:~/devops/kuber-homeworks/3.3/network-policy$ kubectl get networkpolicies
NAME                    POD-SELECTOR   AGE
allow-egress-backend    app=backend    16s
allow-egress-dns        <none>         16s
allow-egress-frontend   app=frontend   16s
allow-ingress-backend   app=backend    16s
allow-ingress-cache     app=cache      16s
default-deny-egress     <none>         16s
default-deny-ingress    <none>         17s
```

### Deployments  
[frontend](main/10-frontend.yaml)  
[backend](main/20-backend.yaml)  
[cache](main/30-cache.yaml)  

### Network-policy

[default-deny-ingress](main/00-default-deny-ingress.yaml)  
[default-deny-egress](main/10-default-deny-egress.yaml)  
[allow-egress-dns](main/20-allow-egress-dns.yaml)  
[allow-ingress-backend](main/30-allow-ingress-backend.yaml)  
[allow-egress-frontend](main/40-allow-egress-frontend.yaml)  
[allow-ingress-cache](main/50-allow-ingress-cache.yaml)  
[allow-egress-backend](main/60-allow-egress-backend.yaml)  




    





